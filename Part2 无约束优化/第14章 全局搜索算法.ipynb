{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 14.2 Nelder-Mead 单纯形法\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 模拟退火法\n",
    "\n",
    "本小节讲的是模拟退火算法在优化问题中的应用。我们首先假定需要求解的优化问题是\n",
    "\n",
    "$$\n",
    "\\mathrm{maximize}\\quad f(x)\\\\\\\\\n",
    "\\mathrm{subject \\quad to} \\quad x \\in \\Omega\n",
    "$$\n",
    "\n",
    "我们这一章讲的是全局的最优搜索算法。而朴素随机搜索算法，会常常让我们陷入**局部最优解**。而**模拟退火算法**以一定的概率来接受一个比当前解要差的解，因此有可能会跳出这个局部的最优解，达到全局的最优解。\n",
    "\n",
    "先让我们看一看朴素随机搜索算法是如何让我们陷入局部最优解的：\n",
    "\n",
    ">**朴素随机搜索算法**<br>\n",
    "1. 令$k:=0$, 选定初始点$x^{(0)} \\in \\Omega$。\n",
    "2. 从$N(x^{(k)})$中随机选定一个备选点$z^{(k)}$。\n",
    "3. 如果$f(z^{(k)})<f(x^{(k)})$, 则令$x^{(k+1)}=z^{(k)}$,否则令$x^{(k+1)}=x^{(k)}$。\n",
    "4. 如果满足停止规则，解停止迭代。\n",
    "5. 令$k:=k+1$,回到第二步。\n",
    "\n",
    "算法中的$N(x)$表示的是接近$x$的“邻域”，而根据$N(x)$随机选定一个备用点，指的是**存在一个位于$N(x)$上的分布函数**，根据这一分布函数得到的采样点。常常使用**均匀分布**作为$N(x)$上的分布函数。\n",
    "\n",
    "\n",
    "### 模拟退火算法\n",
    "\n",
    "正如前面所说的，朴素随机搜索算法当$N(x)$足够小的时候，会将最优解“卡”在局部最优的地方。既然我们说“邻域”$N(x)$足够小会造成这个问题，那么我们将所谓的邻域扩充到整个数据集呢？这样虽然可以找到全局最优解，但是搜索的过程会变得很慢。而**模拟退火算法要解决的就是这样的问题**：\n",
    "\n",
    ">**模拟退火算法**\n",
    "1. 令$k:=0$, 选定初始点$x^{(0)} \\in \\Omega$。\n",
    "2. 从$N(x^{(k)})$中随机选定一个备选点$z^{(k)}$。\n",
    "3. 设置一枚特别的硬币，使其在一次抛投中出现正面的概率为$p(k,f(z^{(k)}), f(x^{(k)}))$。抛一枚该硬币，如果出现正面，令$x^{(k+1)}=z^{(k)}$,否则令$x^{(k+1)}=x^{(k)}$\n",
    "4. 如果满足停止规则，解停止迭代。\n",
    "5. 令$k:=k+1$,回到第二步。\n",
    "\n",
    "模拟退火法与朴素随机搜索算法之间的最大区别在于步骤3 ，在这一步骤中,模拟退火算法以一定的概率选择备选点作为下一次迭代点，即使这个备选点比当前的迭代点要差。这一概率称为**接受概率**。**接受概率应该进行合理的设定，才能保证迭代过程的正确进行**。常用的接受概率为\n",
    "\n",
    "$$\n",
    "p(k, f(z^{(k)}), f(x^{(k)}))=\\mathrm{min}\\{1, \\mathrm{exp}(-(f(z^{(k)})-f(x^{(k)}))/T_k)\\}\n",
    "$$\n",
    "\n",
    "上面的**接受概率**中的$T_k$，称为温度进度表或冷却进度表。这种形式的接受概率是由玻尔兹曼提出的。使得模拟退火算法等价于Gibbs 采样器(基于Gibbs\n",
    "分布的一种概率采样方法) 。\n",
    "\n",
    "**Hajek**给出了一个合适的冷却进度表:\n",
    "$$\n",
    "T_k=\\frac{\\gamma}{\\mathrm{log}(k+2)}\n",
    "$$\n",
    "\n",
    "其中， $\\gamma$>0 为常数，需要根据具体问题确定(需要足够大，以保证算法能够跳出局部极小点附近的区域\n",
    "\n",
    "***从直观上进行理解，一开始，希望能够在整个可行集内进行搜索，随着迭代的开展，搜索的范围应该集中到全局极小点的附近区域，而不是遍历整个可行集。换句话说，最开始，算法在可行集内跳来跳去，以尽可能跳出局部极小点附近的区域，随着时间的推移，算法开始稳定在全局极小点附近的区域，将更多的时间投入到这一区域的搜索中。***\n",
    "\n",
    "\n",
    "\"退火\"一词来自于冶金业，是一种能够改善金属品质的技术。基本的操作方式为先将金属加热到一定程度，然后以可控的方式对其进行冷却。首先，当金属被加热时，其中的原子开始变得活跃，脱离了原来的位置，内能增加。然后，随着冷却的进行，原子逐渐变得有序，内能减少。如果冷却过程足够慢，那么可以保证最终的内能将低于开始阶段的内能，这样可以改善金属的晶体结构，并减少存在的缺陷。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4 粒子群算法\n",
    "**粒子群优化算法也是一种随机搜索算法**，和上面的模拟退火算法不同的是，粒子群优化算法每一次迭代是更新一群(组)迭代点，称为群。群中每个点称为一个粒子。可以将群视为一个无序的群体，其中的每个成员都在移动，意在形成聚集，但移动方向是随机的。**粒子群优化算法旨在模拟动物或昆虫的社会行为，如蜂群、鸟群和挎羊群等的形成过程。**\n",
    "\n",
    "### 基本的粒子群优化算法\n",
    "\n",
    ">**gbest 版的粒子群优化算法**\n",
    "1. 令$k:=0$。随机产生一个初始的粒子群，即产生$d$个粒子的位置$x_i^{(0)}$。及其对应的速度$v_i^{(0)}, p_i^{(0)}, i=1,2,...,d$;另$g^{(0)}=\\mathrm{arg min_{x\\in|x_1^{(0)},...,x_d^{(0)}|}}f(x)$。\n",
    "2. 针对每个$i=1,2,...,d$, 随机产生两个$n$维向量$r_i^{(k)}$和$s_i^{(k)}$，按照均匀分布的原则抽取$(0,1)$中的元素。令\n",
    "$$\n",
    "v_i^{(k+1)}=\\omega v_i^{(k)}+c_1r_i^{(k)}\\circ (p_i^{(k)}-x_i^{(k)})+c_2s_i^{(k)}\\circ (g_i^{(k)}-x_i^{(k)})\\\\\\\\\n",
    "x_i^{(k+1)}=x_i^{(k)}+v_i^{(k+1)}\n",
    "$$\n",
    "3. 针对每个$i=1,2,...,d$, 如果$f(x_i^{(k+1)})<f(p_i^{k})$,令$p_i^{k+1}=x_i^{(k+1)}$; 否则， 令$p_i^{(k+1)}=p_i^{(k)}$\n",
    "4. 如果存在$i=\\{1,...,d\\}$，使得$f(x_i^{(k+1)})<f(g^{(k)})$, 则令$i^*=\\mathrm{arg min}_if(x^{(k+1)_i})$, $g^{(k+1)}=x_{i^*}^{(k+1)}$;否则， 令$g^{(k+1)}=g^{(k)}$\n",
    "5. 如果满足停止条件，就停止迭代。\n",
    "6. 令$k:=k+1$， 回到第2步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.5 遗传算法\n",
    "\n",
    "所谓**遗传算法就需遵循“适者生存，优胜劣汰”的原则。** 我们首先假定需要求解的优化问题是\n",
    "\n",
    "$$\n",
    "\\mathrm{maximize}\\quad f(x)\\\\\\\\\n",
    "\\mathrm{subject \\quad to} \\quad x \\in \\Omega\n",
    "$$\n",
    "\n",
    "因为**遗传算法是从遗传理论基础上得到的**，所以，我们先了解一下遗传学的基本术语：\n",
    "\n",
    "- 染色体和表达模式<br>\n",
    "     一般的优化问题，我们都是**直接**从可行集里面得到最优解。而**遗传算法**先对这些点进行**编码**后再进行操作。\n",
    "- 选择和进化步骤<br>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
